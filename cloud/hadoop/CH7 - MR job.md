# CHAPTER 7

# 7.1 맵리듀스 잡 실행 상세분석

- Job 객체의 submit()로 잡을 실행한다.
    - + waitForCompetion()을 호출한다면?
        - 잡이 제출되지 않았으면?
        - 잡을 제출하고 종료할떄까지 기다린다.
    - 기본 MR API에는 submitJob, runJob 둘다 있음
- 잡을 실행하는 과정
    1. 클라이언트: MR 잡 제출
    2. YARN RM: 클러스터에 리소스 할당 제어
    3. YARN NM: 클러스터의 각 머신에 컨테이너 시작
    4. MR의 AM: 잡을 수행하는 태스크를 제어.
    5. HDFS: 서로 다른 단계 사이에서 리소스 파일을 공유하는데 사용

## 7.1.1 잡 제출

- submit() 하면 JobSubmitter 인스턴스를 생성하고 submitJobInternal 메소드 호출
- 잡을 제출하고 나면 waitForCompletion이 1초마다 잡의 진행상황을 모니터링
- JobSubmitter의 잡 제출 과정
    - RM에 새로운 애플리케이션 ID를 요청
        - 잡의 출력 디렉토리가 지정되어야 한다.
        - 입력 스플릿 (input split)이 계산. 입력경로가 없는 이유같이 스플릿을 계산할 수 없으면 에러
    - 잡 실행에 필요한 파일들을 같은 리소스를 HDFS에 복사.
    - 리소스 매니저의 submitApplication을 호출해 잡 제출

## 7.1.2 잡 초기화

- 리소스 매니저가 잡 제출을 받으면, YARN 스케줄러에 요청 전달
    - 스케줄러는 컨테이너를 할당해서 MR AppMaster 프로세스를 시작
        - 자바 어플리케이션
    - 잡 초기화 시 잡의 진행 상태를 추적하는 bookkeeping 객체 생성
    - 입력 스플릿을 HDFS에서 가져온다
    - 각 스플릿 별로 Map 태스크 객체 생성하고 리듀서 수 만큼 리듀서 객체 생성
- AppMaster는 태스크를 실행할 방법을 결정
    - 잡의 크기가 작으면 자신의 JVM에서 실행 (우버 태스크)
        - 작은 잡이란 10개 미만의 매퍼, 하나의 리듀서, HDFS 블록 하나보다 작은 입력의 크기

## 7.1.3 태스크 할당

- 우버 태스크로 실행하기 적합하지 않으면
    - RM에 모든 맵/리듀스 태스크를 위한 컨테이너를 요청
    - 맵이 끝나야 리듀스가 시작되니까 맵 태스크 요청이 먼저고, 우선순위도 높다.
- 리듀스 태스크야 어디서 실행되든 상관은 없는데,
    - 맵 태스크는 data locality를 지켜야한다.
        - 최적: 입력 스플릿이 있는 노드에서 맵 태스크 실행 (데이터가 로컬)
        - 대안: 입렵 스플릿이 있는 노드는 아니지만 그게 동일한 랙에 있음 (랙 로컬)

## 7.1.4 태스크 실행

- RM이 컨테이너를 위한 리소스를 태스크들에게 할당하고나면
    - AppMaster는 NM과 통신하며 컨테이너를 시작
    - 태스크 실행 전에 필요한 리소스들을 HDFS에서 가져온다.
    - 각 태스크는 YarnChild 자바 어플리케이션으로 실행
        - 전용 JVM에서 실행하므로 얘네에 문제가 생겨도 NM은 영향받지 않는다.

### 스트리밍

- 사용자의 실행 파일을 시작하고 이와 통신하는 MR 태스크를 실행
    - STDIO로 통신한다.

## 7.1.5 진행 상황과 상태 갱신

- MR 잡은 시간이 오래 걸리는 배치 잡이다
    - 따라서 잡의 피드백을 받는게 중요하다
    - 잡과 개별 태스크는 상태 정보를 가진다.
    - 이걸 클라이언트한테 어떻게 전달할까?
- 태스크는 자신의 진행상황을 추적
    - 맵: 처리한 입력 데이터의 비율
    - 리듀스: 얘는 조금 복잡하다. 추정을 위해 전체 진행 과정을 총 세부분으로 나눈다. (복사, 정렬, 리듀스)
- 이벤트를 세는 카운터
    - 프레임워크에 내장된 카운터(ex. 맵의 출력 레코드 수 세기)
    - 사용자 정의 카운터
- MR 태스크 실행 시 자식 프로세스는 부모인 AppMaster와 통신
    - 진행상황과 상태정보를 포함하여 3초마다 보고
- 결과적으로 클라이언트는 Job의 getStatus()를 이용해 상태 정보를 가져온다.

## 7.1.6 잡 완료

- 마지막 태스크가 완료되었다면 상태가 성공으로 바뀐다.
    - 사용자에게 메세지를 보내고
    - waitForCompletion() 메소드 반환
- HTTP로 잡 통지를 받는 콜백 설정도 가능하다.

# 7.2 실패

- 사용자의 잡이 죽으면 어떡하냐 !

## 7.2.1 태스크 실패

- MR 태스크에서 런타임 예외 발생
    - AppMaster에게 에러 보고 (사용자 로그에 기록된다)
    - 실패로 표시, 해당 컨테이너를 풀어준다.
- 태스크 JVM이 갑작스럽게 종료
    - 노드매니저가 이를 감지하고 AppMaster에게 알려준다.
- 행이 걸린 태스크
    - AppMaster는 진행 상황 갱신이 안되면 해당 태스크를 실패로 표시
    - 타임아웃은 보통 10분
    - 타임아웃이 0으로 설정되면 비활성화
        - 이럴때 행 걸린 태스크가 있으면 클러스터 전체적으로 악영향
- AppMaster가 태스크 실패를 알게 되면 다시 스케줄링
    - 실패했던 노드 매니저에 동일하게 스케줄링은 피한다
    - 태스크가 4번 실패하면 재시도 않는다.
- 일부 태스크가 실패해도 잡은 계속되길 원할 수 있다
    - 허용되는 태스크 실패의 최대 비율 지정할 수 있다.
    - 강제 종료는 실패와 다르다 (시도 횟수에 포함되지 않음)

## 7.2.2 애플리케이션 마스터(AppMaster) 실패

- 어플리케이션 또한 실패 시 재시도를 한다.
    - 기본값 2
    - 두번 실패하면 잡의 실패로 끝
    - 이 값은 YARN 클러스터에서 일괄적으로도 제한을 줄 수 있다.
- 복구 작업 방식
    - AppMaster는 주기적으로 RM에게 heartbeat를 보낸다.
    - 실패가 나면 RM이 감지해서 새로운 컨테이너에 새로운 마스터 인스턴스를 시작
    - MR의 경우 잡 히스토리에서 태스크들의 상태를 복구해서 재실행할 필요는 없다.
- MR 클라이언트는 getJobStatus를 AppMaster에서 가져오잖아
    - 그래서 AppMaster가 실패하면 새 마스터 인스턴스의 위치를 알아야한다.
    - 잡 초기화 시 RM에 마스터의 주소를 요청하고 이를 캐싱해둔다.
    - 새로운 마스터가 할당되면 기존 주소로는 타임아웃이 발생하고, 이러면 클라이언트는 RM에 새로운 주소를 요청한다.

## 7.2.3 노드 매니저 실패

- NM이 실패/느리게 수행하면
    - RM에 heartbeat 전송 중단
    - 매우 드물게 전송
    - 10분(얘도 설정가능)동안 한번도 안오면 해당 컨테이너를 스케줄링 노드풀에서 제거
- 실패한 NM에서 실행중이던 AppMaster들은 앞에서 본 것 마냥 복구
    - 또한 완료되지 않은 job(Map 태스크만 성공)을 재실행해야한다.
        - NM에 저장된 job의 중간결과를 (맵 태스크 결과) 리듀서가 접근할 수 없다.
- 어플리케이션의 실패횟수가 높다면 NM이 실패하지 않아도 NM은 블랙리스트에 등록

## 7.2.4 리소스 매니저 실패

- 지금 계층을 높여가면서 보고 있는데, RM은 전체적으로 리소스 할당해주고 관장하는 역할이잖아
    - RM의 실패는 매우 심각하다
    - 모든 실행중인 잡들이 실패하고 복구를 할 수 없어서 RM은 단일 고장점(single point of failure, **SPOF)**
- HA의 달성을 위해 두개의 RM을 active-standby(활성대기) 상태로 둔다.
    - 실패해도 대기 RM이 역할을 대신한다.
- 실행중인 모든 App들의 정보는 HDFS 같은 고가용 상태 저장소에 보관
    - 복구 가능하다
    - 다만, NM의 정보는 저장하지 않는다.
        - 새로운 RM이 생기고 NM이 첫번째 heartbeat를 보낼때 빠르게 재구축 하면 된다.
- 새로운 RM의 시작
    - 상태 저장소에서 App 정보를 읽어와서 모든 AppMaster를 재시작
- 대기 RM → 활성 RM의로의 전환
    - 어떤 시점에서도 단일 활성 RM이 존재하도록 보장
    - 클라이언트와 NM은 라운드 로빈 방식으로 활성 RM에 연결 될 때까지 연결을 시도한다.

# 7.3 셔플과 정렬

- 모든 리듀서의 입력은 키를 기준으로 정렬되어 있다.
    - 셔플: 정렬을 수행하고 맵의 출력 → 리듀서의 입력으로 전송

## 7.3.1 맵 부분

- 맵 함수는 결과를 바로 디스크에 쓰지 않고 메모리에 일정 크기만큼 쓰고 사전 정렬 수행
    - 각 맵 태스크는 환형 구조의 메모리 버퍼가 있다 (100MB 기본)
        - 여기에 임계치 이상 결과가 쌓이면 백그라운드 스레드가 디스크로 스필한다.
        - 스필하는 동안에도 계속 버퍼에 결과는 남고, 버퍼가 꽉 차면 맵은 블록된다.
    - 디스크로 쓰기 전에 일단 데이터를 리듀서 수에 맞게 파티션으로 나눈다.
        - 각 파티션 내에서 키를 기준으로 인메모리 정렬 수행
        - 컴바이너가 있으면 그것도 수행
    - 여러개의 스필 파일이 생성될수도 있다.
        - 하나의 출력 파일로 병합되고 정렬된다.

## 7.3.2 리듀스 부분

- 맵 출력 파일은 맵 태스크가 있는 서버의 로컬 디스크에 쓰여진다.
- 일반적으로 리듀스 태스크는 클러스터 내의 여러 맵 태스크로부터 출력을 가져온다.
    - 맵 태스크가 끝나자마자 복사해온다.
    - 크기가 충분히 작다면 리듀스 태스크의 JVM 메모리에 복사
    - 버퍼 또는 맵 출력수가 한계치에 도달하면 병합되어 디스크로 스필된다.
    - 얘네가 쌓이면 더 크고 정렬된 형태의 파일로 병합
- 파일을 병합하는 단계
    - 마지막으로 병합할 떄 하나의 파일로 병합하지 않고 리듀스 함수로 곧바로 전송한다.
    - 디스크 IO를 줄이는 방법
    - 파일을 병합할 때 라운드라는 개념이 있고, 병합 계수라는 개념이 있다.
        - 이게 각 상황에 맞게 최적화되어 병합한다.. 신기하네

## 7.3.3 설정 조건

- 일반적으로 셔플에 최대한 많은 메모리를 할당하는게 좋다.
    - 그러면 맵/리듀스가 최대한 적은 메모리를 사용해야한다.
- 맵 측면에서 디스크 스필이 여러번 일어나는건 좋지않다.
- 리듀스 측면에서는 중간 데이터가 모두 메모리에 올라와있어야 유리하다.

# 7.4 태스크 실행

## 7.4.2 투기적 실행

- MR 모델에서는 단 하나의 느린 태스크가 전체 잡 수행을 지연시킬 수 있다.
- 하둡은 태스크 수행이 예상보다 더 느리면 다은 동일한 예비 태스크를 실행한다.
    - 이게 speculative execution, 투기적 실행이라고 하네요
- 이렇게 하는 이유는 뭘까?
    - 일단 모든 태스크의 진행 상황을 기록하여 평균보다 매우 느린 태스크에 대해 적용
    - 똑같은걸 두개 띄워서 먼저 끝나는 쪽의 결과를 취하고 나머지 하나는 강제종료
    - 대신 이게 만능은 아니지. 동일한 버그가 있으면 똑같이 느릴테니까?
- 근데 이걸 끌수도 있다.
    - 궁극적 목적은 잡 실행 시간을 줄이는것
    - 근데 두개를 띄우니까 클러스터의 효율성 측면에서 비용 발생
    - 특히 리듀스에서는 끄는게 좋다.
        - 맵 출력을 인출해와야하고, 이 과정에서 네트워크 트래픽이 증가되니까.

## 7.4.3 출력 커미터

- 잡과 태스크의 깔끔한 성공과 실패를 보장하기 위한 커밋 프로토콜이 존재한다.
    - OutputCommitter
- 여러 태스크 시도중에 하나만 커밋, 나머지는 중단
    - 투기적 시도에서는 먼저 완료된걸 커밋, 나머지는 중단
